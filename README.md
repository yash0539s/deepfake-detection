DeepFake Detection System

Table of Contents

What is DeepFake?

Impact of DeepFake Videos

Project Objectives

Project Pipeline

Pre-processing Workflow

Prediction Workflow

Models Used and Their Architecture

Deployment

Running the Code

Technologies Used

Conclusion

Team

What is DeepFake?
DeepFake refers to AI-generated manipulated videos where a person’s face is replaced with another using advanced deep learning models like Generative Adversarial Networks (GANs).

These models create highly realistic fake videos, making it difficult to distinguish real from fake content.

Impact of DeepFake Videos
Negative Effects:
Misinformation & Fake News: Used to spread false narratives on social media.

Celebrity Impersonation: DeepFake technology is misused for scams and fraudulent activities.

Cybersecurity Threat: Fraudulent video content poses risks to financial institutions and government agencies.

Countermeasures:
Various industries, including film, media, and security agencies, are actively developing DeepFake detection solutions.

Project Objectives
Develop an AI-powered DeepFake detection system.

Train a robust deep learning model to classify videos as REAL or FAKE.

Utilize VGG16 for feature extraction and CNN for classification.

Analyze manipulated frames using face landmark detection and feature extraction.

Deploy a real-time AI-based solution that can be integrated into social media platforms.

Project Pipeline
Step	Description
Step 1	Load the dataset
Step 2	Extract videos from the dataset
Step 3	Convert videos into frames (REAL & FAKE)
Step 4	Detect faces in each frame
Step 5	Extract facial landmarks
Step 6	Analyze variations in facial landmarks
Step 7	Classify videos as REAL or FAKE
Pre-processing Workflow
✔ Convert video into frames.
✔ Detect faces in each frame.
✔ Resize frames to 224×224 pixels.
✔ Normalize pixel values for deep learning training.
✔ Extract facial landmarks to identify inconsistencies.

Prediction Workflow
Extract frames from the input video.

Detect faces using VGG16 feature extraction.

Pass extracted features through a CNN model for classification.

Aggregate frame-wise predictions to classify the entire video as REAL or FAKE.

Models Used and Their Architecture
1️⃣ VGG16 (Feature Extractor)
✔ Pretrained on ImageNet dataset.
✔ Extracts high-level features from video frames.
✔ Fine-tuned deeper layers to adapt to DeepFake datasets.

2️⃣ CNN Model (Classifier)
✔ Convolutional Layers: Extract spatial patterns.
✔ Pooling Layers: Reduce computational complexity.
✔ Fully Connected Layers: Classify input as REAL or FAKE.
✔ Activation Function: sigmoid (Outputs probability between 0 and 1).

Hyperparameters Used
✔ Optimizer: Adam (Adaptive Learning Rate).
✔ Loss Function: Sparse Categorical Cross-Entropy.
✔ Batch Size: 32.
✔ Learning Rate: 0.0001.
✔ Epochs: 20.
✔ Test Accuracy Achieved: 87% ✅

Deployment
✔ Backend: Python Flask API.
✔ Frontend: HTML, CSS, JavaScript.
✔ Processing Time: ~1 minute for a 10-second, 30fps video.

Running the Code
Ensure all dependencies are installed before running the application.

Step 1: Install Required Libraries
bash
Copy
Edit
pip install -r requirements.txt
Step 2: Run the Model
bash
Copy
Edit
python app.py


Step 3: Upload a Video for Detection
✔ The model will process each frame.
✔ The final output will be displayed as REAL or FAKE.

Technologies Used
✔ Programming Languages: Python, HTML, CSS, JavaScript.
✔ Libraries: OpenCV, TensorFlow, Keras, Pandas, NumPy, Seaborn.
✔ Deep Learning Models: VGG16, CNN.
✔ Deployment: Flask.

Conclusion
✅ Successfully developed a DeepFake Detection Model using VGG16 + CNN.
✅ Achieved an accuracy of 87%, making it a reliable solution for real-world applications.

